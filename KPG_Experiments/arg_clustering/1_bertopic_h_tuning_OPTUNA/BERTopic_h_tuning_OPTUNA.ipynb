{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fd7b6dd4-b6d6-416a-b1ad-410a2724a515",
    "_uuid": "793c4d3c-1599-4c8b-a958-b9a50c663b5b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-19T12:57:34.864740Z",
     "iopub.status.busy": "2024-11-19T12:57:34.864095Z",
     "iopub.status.idle": "2024-11-19T12:58:35.380800Z",
     "shell.execute_reply": "2024-11-19T12:58:35.379600Z",
     "shell.execute_reply.started": "2024-11-19T12:57:34.864701Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas numpy torch matplotlib hdbscan umap-learn scikit-learn sentence-transformers\n",
    "!pip install bertopic==0.16.2\n",
    "!pip install optuna\n",
    "!pip install demoji\n",
    "!pip install advertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T13:04:34.467126Z",
     "iopub.status.busy": "2024-11-19T13:04:34.466684Z",
     "iopub.status.idle": "2024-11-19T13:05:06.952830Z",
     "shell.execute_reply": "2024-11-19T13:05:06.951613Z",
     "shell.execute_reply.started": "2024-11-19T13:04:34.467091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!apt-get update -q\n",
    "!apt-get install -y -q libgomp1\n",
    "!wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
    "!dpkg -i google-chrome-stable_current_amd64.deb\n",
    "!apt --fix-broken install -y -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T13:05:59.336936Z",
     "iopub.status.busy": "2024-11-19T13:05:59.336416Z",
     "iopub.status.idle": "2024-11-19T13:06:09.354326Z",
     "shell.execute_reply": "2024-11-19T13:06:09.352640Z",
     "shell.execute_reply.started": "2024-11-19T13:05:59.336892Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T13:05:54.141263Z",
     "iopub.status.busy": "2024-11-19T13:05:54.140036Z",
     "iopub.status.idle": "2024-11-19T13:05:54.147267Z",
     "shell.execute_reply": "2024-11-19T13:05:54.145791Z",
     "shell.execute_reply.started": "2024-11-19T13:05:54.141209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"BROWSER_PATH\"] = \"/usr/bin/google-chrome-stable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T13:06:40.054589Z",
     "iopub.status.busy": "2024-11-19T13:06:40.054026Z",
     "iopub.status.idle": "2024-11-19T13:06:40.069102Z",
     "shell.execute_reply": "2024-11-19T13:06:40.067884Z",
     "shell.execute_reply.started": "2024-11-19T13:06:40.054499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import demoji\n",
    "from statistics import mean\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna import create_study\n",
    "from bertopic import BERTopic\n",
    "from statistics import mean\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import hdbscan\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from umap import UMAP\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from optuna.visualization import plot_optimization_history, plot_parallel_coordinate, plot_param_importances\n",
    "import seaborn as sns\n",
    "import advertools as adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T12:59:49.917353Z",
     "iopub.status.busy": "2024-11-19T12:59:49.916613Z",
     "iopub.status.idle": "2024-11-19T12:59:49.924068Z",
     "shell.execute_reply": "2024-11-19T12:59:49.923046Z",
     "shell.execute_reply.started": "2024-11-19T12:59:49.917318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    return demoji.replace(text, '')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove retweets\n",
    "    text = re.sub(r'^RT[\\s]+', '', text, flags=re.IGNORECASE)\n",
    "    # Remove usernames @\n",
    "    text = re.sub(r'@[^\\s]+', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https\\S+', '', text)\n",
    "    url_words = ['url', 'URL', 'html', 'HTML', 'http', 'HTTP']\n",
    "    for u in url_words:\n",
    "        text = re.sub(u, '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    text = remove_emojis(text)\n",
    "    # Remove extra spaces that may have been introduced\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Return preprocessed text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T12:59:50.096396Z",
     "iopub.status.busy": "2024-11-19T12:59:50.096036Z",
     "iopub.status.idle": "2024-11-19T12:59:50.109183Z",
     "shell.execute_reply": "2024-11-19T12:59:50.108118Z",
     "shell.execute_reply.started": "2024-11-19T12:59:50.096362Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(input_file, stance, topic) -> pd.DataFrame:\n",
    "    '''\n",
    "    Each time we only deal with a single topic and stance.\n",
    "    '''\n",
    "    input_corpus = pd.read_csv(input_file)\n",
    "    input_corpus = input_corpus[input_corpus[\"topic\"] == topic]\n",
    "\n",
    "    if stance == 1:\n",
    "        input_corpus = input_corpus[input_corpus[\"stance\"] == 1]\n",
    "    else:\n",
    "        input_corpus = input_corpus[input_corpus[\"stance\"] == -1]\n",
    "\n",
    "    input_corpus.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Debugging: Check if DataFrame is empty after filtering\n",
    "    if input_corpus.empty:\n",
    "        print(\"No data available for the specified topic and stance.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame\n",
    "\n",
    "    # Preprocess the arguments and store them in a new column\n",
    "    preprocessed_data = [preprocess_text(arg) for arg in input_corpus['argument']]\n",
    "\n",
    "    # Debugging: Check preprocessed data\n",
    "    if not preprocessed_data:\n",
    "        print(\"Preprocessed data is empty. Check the preprocessing function.\")\n",
    "\n",
    "    # Expand the tuples into separate columns\n",
    "    input_corpus['preprocessed_arguments']= preprocessed_data\n",
    "\n",
    "    # Debug output\n",
    "    print(\"Loaded dataset:\")\n",
    "    print(input_corpus.head())\n",
    "    print(f\"Total records: {len(input_corpus)}\")\n",
    "\n",
    "    return input_corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1st brute force approach with defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 15  # Set your desired value\n",
    "n_components = 5  # Set your desired value\n",
    "min_samples_fraction = 1.0  # Set your desired value (as a fraction)\n",
    "selected_arguments_path = '/content/drive/MyDrive/Πτυχιακή/Code/Experiments_Meltemi/train_dev_test_dataset/'\n",
    "output_topic_data = './output_topic_data/'  # Output directory for topic data\n",
    "output_arguments_data = './output_arguments_data/'  # Output directory for arguments data\n",
    "stopwords = list(adv.stopwords['greek'])\n",
    "\n",
    "# Set environment variable to avoid parallelism issues with tokenizers\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "# Set device for torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def topic_modeling(df, output_prefix):\n",
    "    \n",
    "    text_list = df['preprocessed_arguments'].tolist()\n",
    "    embedding_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", trust_remote_code=True)\n",
    "    embeddings = embedding_model.encode(text_list)\n",
    "    umap_model = UMAP(random_state=42, n_neighbors=n_neighbors, n_components=n_components, min_dist=0.00, metric='cosine')\n",
    "    hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=10,  #default\n",
    "                                    metric='euclidean',\n",
    "                                    cluster_selection_method='eom',\n",
    "                                    prediction_data=True)\n",
    "    vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=stopwords, lowercase=True)\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        low_memory=True,\n",
    "        nr_topics=10,\n",
    "        verbose=True,\n",
    "        calculate_probabilities=True,\n",
    "        language=\"multilingual\"\n",
    "    )\n",
    "\n",
    "    topics, probabilities = topic_model.fit_transform(documents=text_list, embeddings=embeddings)\n",
    "\n",
    "    topic_array = np.array(topics)\n",
    "    embeddings_double_t = embeddings.astype('double')\n",
    "\n",
    "    # Calculate DBCV and relative validity\n",
    "    dbcv = hdbscan.validity_index(embeddings_double_t, labels=topic_array, metric='cosine')\n",
    "    #relative_validity = hdbscan.validity.relative_validity_(embeddings_double_t, labels=topic_array, metric='cosine')\n",
    "\n",
    "    df['topic_assignment'] = topics\n",
    "\n",
    "    print(f\"Number of topics: {len(df['topic_assignment'].unique())}\")\n",
    "    print(f\"Number of outliers: {len(df[df.topic_assignment == -1])}\")\n",
    "    print(f\"DBCV: {dbcv}\")\n",
    "    #print(f\"Relative Validity: {relative_validity}\")  # Print the relative validity\n",
    "\n",
    "    # Generate topic labels with 5 representative words\n",
    "    topic_labels_fig = topic_model.generate_topic_labels(nr_words=3,  # Updated to get 5 representative words\n",
    "                                                         topic_prefix=False,\n",
    "                                                         word_length=50,\n",
    "                                                         separator=', ')\n",
    "    topic_model.set_topic_labels(topic_labels_fig)\n",
    "\n",
    "    # Create the figure for document visualization\n",
    "    figure = topic_model.visualize_documents(docs=text_list,\n",
    "                                             embeddings=embeddings,\n",
    "                                             hide_annotations=False,\n",
    "                                             custom_labels=True)\n",
    "\n",
    "    os.makedirs(output_topic_data, exist_ok=True)\n",
    "    # Save each plot with a unique filename based on the output_prefix\n",
    "    #svg_filename = os.path.join(output_topic_data, f'{output_prefix}_cluster_plot.svg')\n",
    "    html_filename = os.path.join(output_topic_data, f'{output_prefix}_cluster_plot.html')\n",
    "    #figure.write_image(svg_filename)\n",
    "    figure.write_html(html_filename)\n",
    "\n",
    "    print(f\"Cluster plot saved to:  {html_filename}\")\n",
    "\n",
    "    # Generate the topic counts and labels for the new DataFrame\n",
    "    topic_counts = df['topic_assignment'].value_counts().reset_index()\n",
    "    topic_counts.columns = ['topic', 'count']\n",
    "\n",
    "    # Correctly map topic IDs to labels using BERTopic's topic representation\n",
    "    topic_labels_dict = {topic_id: ', '.join([word for word, _ in topic_model.get_topic(topic_id)])\n",
    "                         for topic_id in topic_counts['topic'].unique() if topic_id != -1}\n",
    "\n",
    "    # Handle outliers (-1) separately\n",
    "    topic_labels_dict[-1] = \"Outliers\"\n",
    "\n",
    "    # Map the topic labels to the DataFrame\n",
    "    topic_counts['topic_label'] = topic_counts['topic'].map(topic_labels_dict)\n",
    "\n",
    "    # Save the updated DataFrame with topic counts and labels\n",
    "    topic_summary_df = topic_counts[['topic', 'count', 'topic_label']]\n",
    "    summary_output_path = os.path.join(output_topic_data, f\"topic_summary_{output_prefix}.csv\")\n",
    "    topic_summary_df.to_csv(summary_output_path, index=False)\n",
    "\n",
    "    print(f\"Topic summary saved to: {summary_output_path}\")\n",
    "\n",
    "    return df, embeddings, dbcv  #, relative_validity  # Return the relative validity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main dataset\n",
    "arguments_file_path = '/content/drive/MyDrive/Πτυχιακή/Code/Experiments_Meltemi/train_dev_test_dataset/arguments_human_translated_dev.csv'\n",
    "arguments_df = pd.read_csv(arguments_file_path)\n",
    "\n",
    "# Get unique combinations of topic and stance\n",
    "unique_combinations = arguments_df[['topic', 'stance']].drop_duplicates()\n",
    "\n",
    "# Initialize lists for results and metrics\n",
    "results = []\n",
    "dbcv_scores = []\n",
    "\n",
    "seed_value = 42\n",
    "\n",
    "# Process each unique topic and stance combination\n",
    "for _, row in unique_combinations.iterrows():\n",
    "    topic = row['topic']\n",
    "    stance = row['stance']\n",
    "    print(f\"Processing topic: {topic}, stance: {stance}\")\n",
    "\n",
    "    # Load dataset based on the topic and stance\n",
    "    filtered_df = load_dataset(arguments_file_path, stance, topic)\n",
    "\n",
    "    if not filtered_df.empty:\n",
    "        # Apply topic modeling\n",
    "        output_prefix = f\"{topic}_{stance}\".replace(\" \", \"_\")\n",
    "        processed_df, embeddings, dbcv = topic_modeling(filtered_df, output_prefix)\n",
    "        results.append(processed_df)\n",
    "        dbcv_scores.append(dbcv)\n",
    "    else:\n",
    "        print(f\"No data found for topic: {topic}, stance: {stance}\")\n",
    "\n",
    "# Compute average DBCV score\n",
    "average_dbcv = np.mean(dbcv_scores)\n",
    "print(f\"Average DBCV score across all topics: {average_dbcv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Optuna Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T12:59:50.182322Z",
     "iopub.status.busy": "2024-11-19T12:59:50.181935Z",
     "iopub.status.idle": "2024-11-19T12:59:50.200958Z",
     "shell.execute_reply": "2024-11-19T12:59:50.199835Z",
     "shell.execute_reply.started": "2024-11-19T12:59:50.182288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def topic_modeling(df, output_prefix, n_neighbors, n_components, min_samples_fraction, cluster_selection_method):\n",
    "    cluster_size = int(len(df) / 50)\n",
    "    if cluster_size < 3:\n",
    "        cluster_size = 3\n",
    "\n",
    "    print(f\"Cluster size: {cluster_size}\")\n",
    "\n",
    "    min_samples = int(min_samples_fraction * cluster_size)\n",
    "    if min_samples < 2:\n",
    "        min_samples = 2\n",
    "\n",
    "    print(f\"Min samples: {min_samples}\")\n",
    "\n",
    "    text_list = df['argument'].tolist()\n",
    "    embedding_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", trust_remote_code=True)\n",
    "\n",
    "    embeddings = embedding_model.encode(text_list)\n",
    "\n",
    "    # Adjust hyperparameters passed to UMAP and HDBSCAN\n",
    "    umap_model = UMAP(random_state=42, n_neighbors=n_neighbors, n_components=n_components, min_dist=0.00, metric='cosine')\n",
    "    hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=cluster_size,\n",
    "                                    metric='euclidean',\n",
    "                                    cluster_selection_method=cluster_selection_method,  # Use the passed parameter\n",
    "                                    min_samples=min_samples,\n",
    "                                    prediction_data=True)\n",
    "    vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=stopwords, lowercase=True)\n",
    "\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        nr_topics=10,\n",
    "        verbose=True,\n",
    "        calculate_probabilities=True\n",
    "    )\n",
    "\n",
    "    topics, probabilities = topic_model.fit_transform(documents=text_list, embeddings=embeddings)\n",
    "\n",
    "    topic_array = np.array(topics)\n",
    "    embeddings_double_t = embeddings.astype('double')\n",
    "\n",
    "    # Calculate DBCV score\n",
    "    dbcv = hdbscan.validity_index(embeddings_double_t, labels=topic_array, metric='cosine')\n",
    "\n",
    "    print(f\"DBCV: {dbcv}\")\n",
    "    return dbcv\n",
    "\n",
    "\n",
    "def objective(trial, df, csv_file):\n",
    "    # Suggest values for each hyperparameter\n",
    "    n_neighbors = trial.suggest_categorical('n_neighbors', [3,5,10,15])\n",
    "    n_components = trial.suggest_categorical('n_components', [2,5,7])\n",
    "    min_samples_fraction = trial.suggest_categorical('min_samples_fraction', [0.5, 1.0])\n",
    "    cluster_selection_method = trial.suggest_categorical('cluster_selection_method', ['eom', 'leaf'])  # New parameter\n",
    "\n",
    "    # Perform topic modeling and get the DBCV score\n",
    "    dbcv_score = topic_modeling(\n",
    "        df,\n",
    "        output_prefix=os.path.splitext(csv_file)[0],\n",
    "        n_neighbors=n_neighbors,\n",
    "        n_components=n_components,\n",
    "        min_samples_fraction=min_samples_fraction,\n",
    "        cluster_selection_method=cluster_selection_method  # Pass the new parameter\n",
    "    )\n",
    "    # Report intermediate DBCV score to Optuna\n",
    "    trial.report(dbcv_score, step=trial.number)\n",
    "\n",
    "    # Handle pruning based on the intermediate value.\n",
    "    if trial.should_prune():\n",
    "      raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return dbcv_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T13:08:30.460012Z",
     "iopub.status.busy": "2024-11-19T13:08:30.459354Z",
     "iopub.status.idle": "2024-11-19T13:08:46.798093Z",
     "shell.execute_reply": "2024-11-19T13:08:46.795847Z",
     "shell.execute_reply.started": "2024-11-19T13:08:30.459962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "selected_arguments_path = '/kaggle/input/meltemi-data/'\n",
    "# Output directories for topic and arguments data\n",
    "output_topic_data = './'\n",
    "output_arguments_data = './'\n",
    "\n",
    "# Set environment variable to avoid parallelism issues with tokenizers\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "# Set device for torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Load the main CSV file that contains topics and stances\n",
    "arguments_file_path = os.path.join(selected_arguments_path, 'arguments_human_translated_dev.csv')\n",
    "arguments_df = pd.read_csv(arguments_file_path)\n",
    "\n",
    "# Get unique combinations of topic and stance\n",
    "unique_combinations = arguments_df[['topic', 'stance']].drop_duplicates()\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "dbcv_scores = []  # List to store DBCV scores for averaging\n",
    "seed_value = 42\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through each unique combination of topic and stance\n",
    "for _, row in unique_combinations.iterrows():\n",
    "    topic = row['topic']\n",
    "    stance = row['stance']\n",
    "    print(f\"Processing topic: {topic}, stance: {stance}\")\n",
    "\n",
    "    # Load dataset based on the topic and stance\n",
    "    filtered_df = load_dataset(arguments_file_path, stance, topic)\n",
    "\n",
    "    # Check if the filtered dataset is not empty\n",
    "    if not filtered_df.empty:\n",
    "        # Create an Optuna study for each topic-stance combination\n",
    "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=seed_value), pruner=MedianPruner())\n",
    "\n",
    "        # Optimize the objective function for the current dataset\n",
    "        study.optimize(lambda trial: objective(trial, filtered_df, f\"{topic}_{stance}\"), n_trials=100)\n",
    "\n",
    "        # Save the best trial results for each combination\n",
    "        print(f\"Best trial for topic: {topic}, stance: {stance}\")\n",
    "        trial = study.best_trial\n",
    "        print(f\"DBCV Score: {trial.value}\")\n",
    "        print(f\"Best hyperparameters: {trial.params}\")\n",
    "\n",
    "        # Save the optimization history plot\n",
    "        optimization_history = plot_optimization_history(study)\n",
    "        optimization_history_image_path = os.path.join(output_topic_data, f\"{topic}_{stance}_optimization_history.png\")\n",
    "        optimization_history.write_image(optimization_history_image_path)\n",
    "        print(f\"Optimization history saved to: {optimization_history_image_path}\")\n",
    "\n",
    "        # Save the parallel coordinate plot\n",
    "        parallel_coordinate = plot_parallel_coordinate(study)\n",
    "        parallel_coordinate_image_path = os.path.join(output_topic_data, f\"{topic}_{stance}_parallel_coordinate.png\")\n",
    "        parallel_coordinate.write_image(parallel_coordinate_image_path)\n",
    "        print(f\"Parallel coordinate plot saved to: {parallel_coordinate_image_path}\")\n",
    "\n",
    "        # Save the hyperparameter importances plot\n",
    "        param_importance = plot_param_importances(study)\n",
    "        param_importance_image_path = os.path.join(output_topic_data, f\"{topic}_{stance}_param_importances.png\")\n",
    "        param_importance.write_image(param_importance_image_path)\n",
    "        print(f\"Hyperparameter importances plot saved to: {param_importance_image_path}\")\n",
    "\n",
    "        # Store the DBCV score for averaging\n",
    "        dbcv_scores.append(trial.value)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'topic': topic,\n",
    "            'stance': stance,\n",
    "            'dbcv_score': trial.value,\n",
    "            'best_hyperparameters': trial.params\n",
    "        })\n",
    "\n",
    "# Output all results\n",
    "for result in results:\n",
    "    print(f\"Topic: {result['topic']}, Stance: {result['stance']}\")\n",
    "    print(f\"Best DBCV Score: {result['dbcv_score']}\")\n",
    "    print(f\"Best Hyperparameters: {result['best_hyperparameters']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Calculate and display the average DBCV score across all topic-stance combinations\n",
    "if dbcv_scores:\n",
    "    average_dbcv_score = sum(dbcv_scores) / len(dbcv_scores)\n",
    "    print(f\"\\nAverage DBCV Score across all topic-stance combinations: {average_dbcv_score:.4f}\")\n",
    "else:\n",
    "    print(\"No DBCV scores were obtained.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5621726,
     "sourceId": 9286827,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
